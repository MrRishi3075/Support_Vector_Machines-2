{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae0d98ec-dd6c-4365-9999-bf3fe983894e",
   "metadata": {},
   "source": [
    "##### Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?\n",
    "##### Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\n",
    "##### Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
    "##### Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?\n",
    "##### Q5. Assignment:\n",
    "- Import the necessary libraries and load the dataset.\n",
    "- Split the dataset into training and testing set.\n",
    "- Preprocess the data using any technique of your choice (e.g. scaling, normaliMation).\n",
    "- Create an instance of the SVC classifier and train it on the training data.\n",
    "- Use the trained classifier to predict the labels of the testing data.\n",
    "- Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy, precision, recall, F1-score)\n",
    "- Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to improve its performance.\n",
    "- Train the tuned classifier on the entire dataset.\n",
    "- Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a25438-6338-4fa1-a1cf-c47be38ea9b0",
   "metadata": {},
   "source": [
    "#### Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?\n",
    "\n",
    "**In machine learning, especially in support vector machines (SVM), a kernel function is used to transform input data into a higher-dimensional space. Polynomial functions are a type of kernel function. The polynomial kernel is defined as  K(x,y)=(x⋅y+c)d , where**\n",
    "- c is a constant and \n",
    "- d is the degree of the polynomial.\n",
    "\n",
    "- The relationship is that polynomial functions are used as kernel functions in SVM to handle non-linear decision boundaries. SVM with a polynomial kernel is capable of capturing complex relationships in the data by mapping it to a higher-dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cea6c88-eeca-4e60-a991-137a66183d32",
   "metadata": {},
   "source": [
    "#### Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\n",
    "\n",
    "**Here's an example of implementing an SVM with a polynomial kernel using Scikit-learn:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb5d0f2-b4f3-4f47-a8d0-6e3c9e4e7853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset (replace with your dataset)\n",
    "data = datasets.load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data (scaling in this example)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an instance of the SVC classifier with a polynomial kernel\n",
    "svc_classifier = SVC(kernel='poly', degree=3, C=1.0)\n",
    "\n",
    "# Train the classifier\n",
    "svc_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use the trained classifier to predict labels of the testing data\n",
    "y_pred = svc_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance using accuracy as a metric\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c87311c-11a9-4892-a47a-18b372bac129",
   "metadata": {},
   "source": [
    "#### Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
    "\n",
    "**In Support Vector Regression (SVR), epsilon (ε) is a parameter that determines the width of the margin around the regression line within which no penalty is incurred. Larger values of epsilon result in a wider margin, allowing more data points to be within the margin without incurring a penalty.**\n",
    "\n",
    "- Increasing the value of epsilon generally leads to an increase in the number of support vectors. A larger epsilon allows more points to be considered as part of the support vectors, as the margin becomes wider. This can make the SVR model less sensitive to individual data points and outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6cb1ef-dccf-4cb8-92dc-05ba1faa3d91",
   "metadata": {},
   "source": [
    "#### Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?\n",
    "\n",
    "**Kernel Function:**\n",
    "- The choice of kernel function determines the mapping of data into a higher-dimensional space. Different kernels (linear, polynomial, radial basis function, etc.) may perform better on different types of data. Experimentation is crucial to finding the most suitable kernel.\n",
    "\n",
    "**C Parameter:**\n",
    "- C is the regularization parameter, balancing the trade-off between a smooth decision boundary and fitting the training data. Smaller C values lead to a smoother decision boundary, while larger C values result in a more complex decision boundary that fits the training data more closely. If the model is overfitting, try reducing C; if it is underfitting, try increasing C.\n",
    "\n",
    "**Epsilon Parameter:**\n",
    "- Epsilon (ε) defines the width of the margin around the regression line. A larger epsilon allows for a wider margin, making the model less sensitive to individual data points. Increasing epsilon can be useful when dealing with noisy data or outliers.\n",
    "\n",
    "**Gamma Parameter:**\n",
    "- Gamma (γ) defines how far the influence of a single training example reaches. Higher values of gamma lead to more localized decision boundaries, making the model sensitive to small-scale features. Lower values of gamma result in a more global influence. If the model is overfitting, try reducing gamma; if it is underfitting, try increasing gamma.\n",
    "\n",
    "**It's essential to perform hyperparameter tuning (e.g., using GridSearchCV) to find the optimal values for these parameters based on cross-validation performance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a179d641-adb9-4ae8-9db1-ad8f5be7fdf6",
   "metadata": {},
   "source": [
    "#### Q5. Assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd057513-1b6e-4094-ac56-eae12cbfc944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Best Hyperparameters: {'C': 0.1, 'degree': 2, 'kernel': 'linear'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['trained_classifier.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Load the dataset (replace with your dataset)\n",
    "data = datasets.load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data (scaling in this example)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an instance of the SVC classifier\n",
    "svc_classifier = SVC()\n",
    "\n",
    "# Train the classifier\n",
    "svc_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use the trained classifier to predict labels of the testing data\n",
    "y_pred = svc_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance using accuracy as a metric\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'poly', 'rbf'], 'degree': [2, 3, 4]}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=3)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best Hyperparameters: {best_params}')\n",
    "\n",
    "# Train the tuned classifier on the entire dataset\n",
    "final_svc_classifier = SVC(**best_params)\n",
    "final_svc_classifier.fit(X, y)\n",
    "\n",
    "# Save the trained classifier to a file for future use\n",
    "joblib.dump(final_svc_classifier, 'trained_classifier.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecd8cb9-85bf-4c05-a74e-7e45dd4248f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
